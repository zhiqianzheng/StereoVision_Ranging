#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ— äººæœºåŒç›®è§†è§‰é¿éšœç³»ç»Ÿ
åŠŸèƒ½ï¼šæ£€æµ‹éšœç¢ç‰©è·ç¦»å’Œæ–¹ä½ï¼Œæä¾›é¿éšœå†³ç­–
é€‚ç”¨ï¼šæ— äººæœºå®æ—¶é¿éšœå¯¼èˆª
"""

import cv2
import numpy as np
import sys
import os
import time
import json
from enum import Enum
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

# å¯¼å…¥ç›¸æœºé…ç½®
sys.path.append(r'two_vision_calibration/calibration_code/calibration_results')
try:
    import camera_config as config
    print("âœ… æˆåŠŸå¯¼å…¥ç›¸æœºé…ç½®")
    print(f"   åŸºçº¿è·ç¦»: {config.BASELINE_MM:.2f}mm")
    print(f"   ç„¦è·: {config.FOCAL_LENGTH:.2f}pixels")
except ImportError as e:
    print("âŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ç›¸æœºé…ç½®æ–‡ä»¶")
    print("   è¯·ç¡®ä¿å·²è¿è¡Œ stereo_calibration.py ç”Ÿæˆé…ç½®æ–‡ä»¶")
    sys.exit(1)


class ObstacleLevel(Enum):
    """éšœç¢ç‰©å¨èƒç­‰çº§"""
    SAFE = "SAFE"           # å®‰å…¨
    CAUTION = "CAUTION"     # æ³¨æ„
    WARNING = "WARNING"     # è­¦å‘Š  
    DANGER = "DANGER"       # å±é™©
    CRITICAL = "CRITICAL"   # æå±é™©


class Direction(Enum):
    """é£è¡Œæ–¹å‘å»ºè®®"""
    FORWARD = "FORWARD"
    LEFT = "LEFT"
    RIGHT = "RIGHT"
    UP = "UP"
    DOWN = "DOWN"
    BACK = "BACK"
    STOP = "STOP"


@dataclass
class ObstacleInfo:
    """éšœç¢ç‰©ä¿¡æ¯"""
    distance: float         # è·ç¦»ï¼ˆmmï¼‰
    position_x: float       # Xåæ ‡ï¼ˆmmï¼Œç›¸å¯¹ç›¸æœºä¸­å¿ƒï¼‰
    position_y: float       # Yåæ ‡ï¼ˆmmï¼Œç›¸å¯¹ç›¸æœºä¸­å¿ƒï¼‰
    threat_level: ObstacleLevel
    region: str            # æ‰€å±åŒºåŸŸ


@dataclass
class AvoidanceDecision:
    """é¿éšœå†³ç­–"""
    safe_direction: Direction
    threat_level: ObstacleLevel
    closest_obstacle: float
    region_distances: Dict[str, float]
    action_confidence: float


class DroneObstacleAvoidance:
    """æ— äººæœºéšœç¢ç‰©é¿éšœç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–é¿éšœç³»ç»Ÿ"""
        # é¿éšœå‚æ•°è®¾ç½®
        self.safe_distance = 2000      # å®‰å…¨è·ç¦»ï¼ˆmmï¼‰
        self.warning_distance = 1500   # è­¦å‘Šè·ç¦»ï¼ˆmmï¼‰
        self.danger_distance = 1000    # å±é™©è·ç¦»ï¼ˆmmï¼‰
        self.critical_distance = 500   # æå±é™©è·ç¦»ï¼ˆmmï¼‰
        
        # è§†é‡åˆ†åŒºè®¾ç½®ï¼ˆå°†è§†é‡åˆ†æˆ9ä¸ªåŒºåŸŸï¼‰
        self.regions = {
            'top_left': (0, 0, 1, 1),      # (x_start_ratio, y_start_ratio, x_end_ratio, y_end_ratio)
            'top_center': (1, 0, 2, 1),
            'top_right': (2, 0, 3, 1),
            'middle_left': (0, 1, 1, 2),
            'center': (1, 1, 2, 2),
            'middle_right': (2, 1, 3, 2),
            'bottom_left': (0, 2, 1, 3),
            'bottom_center': (1, 2, 2, 3),
            'bottom_right': (2, 2, 3, 3)
        }
        
        # åˆå§‹åŒ–ç«‹ä½“è§†è§‰ç»„ä»¶
        self._init_stereo_vision()
        
        print("ğŸš æ— äººæœºé¿éšœç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
    def _init_stereo_vision(self):
        """åˆå§‹åŒ–ç«‹ä½“è§†è§‰ç»„ä»¶"""
        # åˆ›å»ºç«‹ä½“åŒ¹é…å™¨
        self.stereo_matcher = cv2.StereoSGBM_create(
            minDisparity=0,
            numDisparities=160,
            blockSize=5,
            P1=8 * 3 * 5**2,
            P2=32 * 3 * 5**2,
            disp12MaxDiff=1,
            uniquenessRatio=15,
            speckleWindowSize=0,
            speckleRange=2,
            preFilterCap=63,
            mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY
        )
        
        # åˆ›å»ºWLSæ»¤æ³¢å™¨
        self.wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=self.stereo_matcher)
        self.wls_filter.setLambda(80000)
        self.wls_filter.setSigmaColor(1.2)
        self.right_matcher = cv2.ximgproc.createRightMatcher(self.stereo_matcher)
        
        # åˆ›å»ºæ ¡æ­£æ˜ å°„è¡¨
        self._create_rectify_maps()
        
    def _create_rectify_maps(self):
        """åˆ›å»ºå›¾åƒæ ¡æ­£æ˜ å°„è¡¨"""
        image_size = (config.CAMERA_WIDTH//2, config.CAMERA_HEIGHT)
        
        # å·¦ç›¸æœºæ ¡æ­£æ˜ å°„
        self.map1_left, self.map2_left = cv2.initUndistortRectifyMap(
            config.LEFT_CAMERA_MATRIX,
            config.LEFT_DIST_COEFFS,
            config.RECTIFY_R1,
            config.RECTIFY_P1,
            image_size,
            cv2.CV_16SC2
        )
        
        # å³ç›¸æœºæ ¡æ­£æ˜ å°„
        self.map1_right, self.map2_right = cv2.initUndistortRectifyMap(
            config.RIGHT_CAMERA_MATRIX,
            config.RIGHT_DIST_COEFFS,
            config.RECTIFY_R2,
            config.RECTIFY_P2,
            image_size,
            cv2.CV_16SC2
        )
        
    def compute_3d_points(self, disparity: np.ndarray) -> np.ndarray:
        """è®¡ç®—3Dç‚¹äº‘"""
        # ä½¿ç”¨QçŸ©é˜µé‡æŠ•å½±åˆ°3D
        points_3d = cv2.reprojectImageTo3D(disparity, config.RECTIFY_Q)
        
        # è¿‡æ»¤æ— æ•ˆç‚¹
        mask = disparity > 0
        points_3d[~mask] = [0, 0, 10000]  # æ— æ•ˆç‚¹è®¾ä¸ºè¿œå¤„
        
        return points_3d
        
    def analyze_regions(self, points_3d: np.ndarray) -> Dict[str, ObstacleInfo]:
        """åˆ†æå„åŒºåŸŸçš„éšœç¢ç‰©æƒ…å†µ"""
        h, w = points_3d.shape[:2]
        region_info = {}
        
        for region_name, (x_start, y_start, x_end, y_end) in self.regions.items():
            # è®¡ç®—åŒºåŸŸè¾¹ç•Œ
            x1 = int(w * x_start / 3)
            y1 = int(h * y_start / 3)
            x2 = int(w * x_end / 3)
            y2 = int(h * y_end / 3)
            
            # æå–åŒºåŸŸ3Dç‚¹
            region_points = points_3d[y1:y2, x1:x2]
            
            # è·å–æœ‰æ•ˆæ·±åº¦ç‚¹
            valid_mask = (region_points[:, :, 2] > 0) & (region_points[:, :, 2] < 10000)
            
            if np.any(valid_mask):
                valid_points = region_points[valid_mask]
                
                # æ‰¾åˆ°æœ€è¿‘çš„éšœç¢ç‰©
                distances = valid_points[:, 2]  # Zåæ ‡å°±æ˜¯è·ç¦»
                min_distance = np.min(distances)
                min_idx = np.argmin(distances)
                closest_point = valid_points[min_idx]
                
                # ç¡®å®šå¨èƒç­‰çº§
                threat_level = self._get_threat_level(min_distance)
                
                region_info[region_name] = ObstacleInfo(
                    distance=min_distance,
                    position_x=closest_point[0],
                    position_y=closest_point[1],
                    threat_level=threat_level,
                    region=region_name
                )
            else:
                # æ— æœ‰æ•ˆéšœç¢ç‰©
                region_info[region_name] = ObstacleInfo(
                    distance=float('inf'),
                    position_x=0,
                    position_y=0,
                    threat_level=ObstacleLevel.SAFE,
                    region=region_name
                )
        
        return region_info
    
    def _get_threat_level(self, distance: float) -> ObstacleLevel:
        """æ ¹æ®è·ç¦»ç¡®å®šå¨èƒç­‰çº§"""
        if distance < self.critical_distance:
            return ObstacleLevel.CRITICAL
        elif distance < self.danger_distance:
            return ObstacleLevel.DANGER
        elif distance < self.warning_distance:
            return ObstacleLevel.WARNING
        elif distance < self.safe_distance:
            return ObstacleLevel.CAUTION
        else:
            return ObstacleLevel.SAFE
    
    def make_avoidance_decision(self, region_info: Dict[str, ObstacleInfo]) -> AvoidanceDecision:
        """åšå‡ºé¿éšœå†³ç­–"""
        # æå–å„åŒºåŸŸè·ç¦»
        region_distances = {name: info.distance for name, info in region_info.items()}
        
        # æ‰¾åˆ°æœ€è¿‘éšœç¢ç‰©
        closest_distance = min(region_distances.values())
        overall_threat = self._get_threat_level(closest_distance)
        
        # åˆ†æå‰æ–¹ä¸­å¤®åŒºåŸŸ
        center_distance = region_distances['center']
        center_threat = self._get_threat_level(center_distance)
        
        # å†³ç­–é€»è¾‘
        if center_threat == ObstacleLevel.CRITICAL:
            # ç´§æ€¥åœæ­¢
            safe_direction = Direction.STOP
            confidence = 1.0
        elif center_threat in [ObstacleLevel.DANGER, ObstacleLevel.WARNING]:
            # éœ€è¦é¿éšœ
            left_distance = min(region_distances['middle_left'], region_distances['top_left'], region_distances['bottom_left'])
            right_distance = min(region_distances['middle_right'], region_distances['top_right'], region_distances['bottom_right'])
            up_distance = min(region_distances['top_left'], region_distances['top_center'], region_distances['top_right'])
            down_distance = min(region_distances['bottom_left'], region_distances['bottom_center'], region_distances['bottom_right'])
            
            # é€‰æ‹©æœ€å®‰å…¨çš„æ–¹å‘
            directions = {
                Direction.LEFT: left_distance,
                Direction.RIGHT: right_distance,
                Direction.UP: up_distance,
                Direction.DOWN: down_distance
            }
            
            safe_direction = max(directions, key=directions.get)
            confidence = min(1.0, directions[safe_direction] / self.safe_distance)
            
        elif center_threat == ObstacleLevel.CAUTION:
            # è°¨æ…å‰è¿›
            safe_direction = Direction.FORWARD
            confidence = 0.6
        else:
            # å®‰å…¨å‰è¿›
            safe_direction = Direction.FORWARD
            confidence = 1.0
        
        return AvoidanceDecision(
            safe_direction=safe_direction,
            threat_level=overall_threat,
            closest_obstacle=closest_distance,
            region_distances=region_distances,
            action_confidence=confidence
        )
    
    def create_avoidance_visualization(self, image: np.ndarray, region_info: Dict[str, ObstacleInfo], 
                                     decision: AvoidanceDecision) -> np.ndarray:
        """åˆ›å»ºé¿éšœå¯è§†åŒ–ç•Œé¢"""
        vis_img = image.copy()
        h, w = vis_img.shape[:2]
        
        # ç»˜åˆ¶åŒºåŸŸç½‘æ ¼å’Œéšœç¢ç‰©ä¿¡æ¯
        for region_name, (x_start, y_start, x_end, y_end) in self.regions.items():
            x1 = int(w * x_start / 3)
            y1 = int(h * y_start / 3)
            x2 = int(w * x_end / 3)
            y2 = int(h * y_end / 3)
            
            info = region_info[region_name]
            
            # æ ¹æ®å¨èƒç­‰çº§é€‰æ‹©é¢œè‰²
            color_map = {
                ObstacleLevel.SAFE: (0, 255, 0),      # ç»¿è‰²
                ObstacleLevel.CAUTION: (0, 255, 255), # é»„è‰²
                ObstacleLevel.WARNING: (0, 165, 255), # æ©™è‰²
                ObstacleLevel.DANGER: (0, 0, 255),    # çº¢è‰²
                ObstacleLevel.CRITICAL: (255, 0, 255) # ç´«è‰²
            }
            
            color = color_map[info.threat_level]
            
            # ç»˜åˆ¶åŒºåŸŸè¾¹æ¡†
            cv2.rectangle(vis_img, (x1, y1), (x2, y2), color, 2)
            
            # æ˜¾ç¤ºè·ç¦»ä¿¡æ¯
            if info.distance != float('inf'):
                distance_text = f"{info.distance:.0f}mm"
                cv2.putText(vis_img, distance_text, (x1 + 5, y1 + 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # æ˜¾ç¤ºå†³ç­–ä¿¡æ¯
        decision_y = 30
        cv2.putText(vis_img, f"Decision: {decision.safe_direction.value}", (10, decision_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        decision_y += 30
        cv2.putText(vis_img, f"Threat: {decision.threat_level.value}", (10, decision_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        decision_y += 30
        cv2.putText(vis_img, f"Closest: {decision.closest_obstacle:.0f}mm", (10, decision_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        decision_y += 30
        cv2.putText(vis_img, f"Confidence: {decision.action_confidence:.2f}", (10, decision_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        return vis_img
    
    def process_frame(self, left_img: np.ndarray, right_img: np.ndarray) -> Tuple[AvoidanceDecision, np.ndarray, np.ndarray]:
        """å¤„ç†å•å¸§å›¾åƒï¼Œè¿”å›é¿éšœå†³ç­–å’Œå¯è§†åŒ–"""
        # å›¾åƒæ ¡æ­£
        rectified_left = cv2.remap(left_img, self.map1_left, self.map2_left, cv2.INTER_LINEAR)
        rectified_right = cv2.remap(right_img, self.map1_right, self.map2_right, cv2.INTER_LINEAR)
        
        # è®¡ç®—è§†å·®
        gray_left = cv2.cvtColor(rectified_left, cv2.COLOR_BGR2GRAY)
        gray_right = cv2.cvtColor(rectified_right, cv2.COLOR_BGR2GRAY)
        
        disparity_left = self.stereo_matcher.compute(gray_left, gray_right)
        disparity_right = self.right_matcher.compute(gray_right, gray_left)
        
        disparity_left = disparity_left.astype(np.float32) / 16.0
        disparity_right = disparity_right.astype(np.float32) / 16.0
        
        # WLSæ»¤æ³¢
        disparity = self.wls_filter.filter(disparity_left, gray_left, None, disparity_right)
        
        # è®¡ç®—3Dç‚¹äº‘
        points_3d = self.compute_3d_points(disparity)
        
        # åˆ†æå„åŒºåŸŸ
        region_info = self.analyze_regions(points_3d)
        
        # åšå‡ºé¿éšœå†³ç­–
        decision = self.make_avoidance_decision(region_info)
        
        # åˆ›å»ºå¯è§†åŒ–
        visualization = self.create_avoidance_visualization(rectified_left, region_info, decision)
        
        return decision, visualization, disparity
    
    def run_real_time_avoidance(self, camera_id: int = 20):
        """è¿è¡Œå®æ—¶é¿éšœç³»ç»Ÿ"""
        print("ğŸš å¯åŠ¨æ— äººæœºé¿éšœç³»ç»Ÿ...")
        
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
            return False
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, config.CAMERA_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, config.CAMERA_HEIGHT)
        cap.set(cv2.CAP_PROP_FPS, config.CAMERA_FPS)
        
        print("âœ… é¿éšœç³»ç»Ÿè¿è¡Œä¸­")
        print("ğŸ“– æ“ä½œè¯´æ˜:")
        print("   - ç»¿è‰²åŒºåŸŸï¼šå®‰å…¨")
        print("   - é»„è‰²åŒºåŸŸï¼šæ³¨æ„")
        print("   - æ©™è‰²åŒºåŸŸï¼šè­¦å‘Š")
        print("   - çº¢è‰²åŒºåŸŸï¼šå±é™©")
        print("   - ç´«è‰²åŒºåŸŸï¼šæå±é™©")
        print("   - æŒ‰ 'q'ï¼šé€€å‡º")
        print("   - æŒ‰ 'l'ï¼šä¿å­˜é¿éšœæ—¥å¿—")
        
        cv2.namedWindow('Drone Obstacle Avoidance', cv2.WINDOW_NORMAL)
        
        frame_count = 0
        decisions_log = []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                continue
            
            try:
                # åˆ†ç¦»å·¦å³å›¾åƒ
                height, width = frame.shape[:2]
                left_img = frame[:, :width//2]
                right_img = frame[:, width//2:]
                
                # å¤„ç†é¿éšœ
                decision, visualization, disparity = self.process_frame(left_img, right_img)
                
                # è®°å½•å†³ç­–æ—¥å¿—
                log_entry = {
                    'frame': frame_count,
                    'timestamp': time.time(),
                    'decision': decision.safe_direction.value,
                    'threat_level': decision.threat_level.value,
                    'closest_obstacle': decision.closest_obstacle,
                    'confidence': decision.action_confidence
                }
                decisions_log.append(log_entry)
                
                # åˆ›å»ºæ·±åº¦å›¾å¯è§†åŒ–
                depth_colored = cv2.applyColorMap(
                    cv2.convertScaleAbs(disparity, alpha=255/disparity.max()), 
                    cv2.COLORMAP_JET
                )
                
                # ç»„åˆæ˜¾ç¤º
                combined_display = np.hstack([visualization, depth_colored])
                cv2.imshow('Drone Obstacle Avoidance', combined_display)
                
                frame_count += 1
                
                # æ§åˆ¶å°è¾“å‡ºå†³ç­–
                if frame_count % 30 == 0:  # æ¯ç§’è¾“å‡ºä¸€æ¬¡
                    print(f"ğŸ¯ Frame {frame_count}: {decision.safe_direction.value} | "
                          f"Threat: {decision.threat_level.value} | "
                          f"Closest: {decision.closest_obstacle:.0f}mm | "
                          f"Confidence: {decision.action_confidence:.2f}")
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('l'):
                    # ä¿å­˜å†³ç­–æ—¥å¿—
                    log_filename = f"avoidance_log_{int(time.time())}.json"
                    with open(log_filename, 'w') as f:
                        json.dump(decisions_log, f, indent=2)
                    print(f"ğŸ“ é¿éšœæ—¥å¿—å·²ä¿å­˜: {log_filename}")
                
            except Exception as e:
                print(f"âŒ å¤„ç†é”™è¯¯: {e}")
                continue
        
        cap.release()
        cv2.destroyAllWindows()
        print("âœ… é¿éšœç³»ç»Ÿå·²é€€å‡º")
        return True


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš æ— äººæœºåŒç›®è§†è§‰é¿éšœç³»ç»Ÿ")
    print("å®æ—¶æ£€æµ‹éšœç¢ç‰©æ–¹ä½å’Œè·ç¦»")
    print("=" * 60)
    
    try:
        avoidance_system = DroneObstacleAvoidance()
        avoidance_system.run_real_time_avoidance(config.CAMERA_INDEX)
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()